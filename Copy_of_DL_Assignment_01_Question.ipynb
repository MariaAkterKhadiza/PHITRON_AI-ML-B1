{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaAkterKhadiza/PHITRON_AI-ML-B1/blob/main/Copy_of_DL_Assignment_01_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# DL Assignment 01\n",
        "\n",
        "**Name:**\n",
        "Mariya Dewan\n",
        "\n",
        "\n",
        "**Course Email:**\n",
        "khadizatulmaria2002@gmail.com\n",
        "\n",
        "\n",
        "This is a small assignment that connects topics from Module 1, 2, and 3.  \n",
        "\n",
        "## End of Assignment\n",
        "\n",
        "Before submitting:\n",
        "- Run all cells from top to bottom.  \n",
        "- Check that all answer sections are filled.  \n",
        "- Instruction video ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶¶‡ßá‡ßü‡¶æ Colab ‡¶´‡¶æ‡¶á‡¶≤‡¶ü‡¶ø ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶è‡¶ï‡¶ü‡¶ø Save copy in drive ‡¶ï‡¶∞‡ßá ‡¶®‡¶ø‡¶¨‡¶æ‡•§ ‡¶è‡¶∞‡¶™‡¶∞ Google colab ‡¶è‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶ï‡ßã‡¶°‡¶ó‡ßÅ‡¶≤‡ßã ‡¶ï‡¶∞‡¶¨‡ßá ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßá‡¶á ‡¶´‡¶æ‡¶á‡¶≤‡¶ü‡¶ø ‚ÄòAnyone with the link‚Äô & ‚ÄòView‚Äô Access ‡¶¶‡¶ø‡ßü‡ßá ‡¶´‡¶æ‡¶á‡¶≤‡¶ü‡¶ø‡¶∞ Shareble Link ‡¶ü‡¶ø ‡¶∏‡¶æ‡¶¨‡¶Æ‡¶ø‡¶ü ‡¶ï‡¶∞‡¶¨‡ßá‡•§"
      ],
      "metadata": {
        "id": "JcVoA-oxVACn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 01: [ Marks 10 ]\n",
        "\n",
        "What is a perceptron?\n",
        "Explain its three main components and their roles."
      ],
      "metadata": {
        "id": "d18z86IcVO3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write** Answer 01:\n",
        "\n",
        "Perceptron is a type of Artificial Neural Network and basically it's inspire from biological neural.A basic unit of a ml model used for binary classfication.example:(yes/no,0/1,true/false)for decision making.\n",
        "\n",
        "\n",
        "\n",
        "**There are three main feature/components:**\n",
        "\n",
        "1.Input + Weights\n",
        "\n",
        "\n",
        "2.bias & summation\n",
        "\n",
        "\n",
        "3.Activation Function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Their roles:**\n",
        "\n",
        "**1. Inputs and Weights**\n",
        "\n",
        "Inputs are the features (X1,X2,X3....xn).\n",
        "\n",
        "\n",
        "Each input has a corresponding weight (W1,W2,W3...Wn).\n",
        "\n",
        "**Mathematical Form **\n",
        "        x1w1+x2w2+x3w3+...........+xnwn\n",
        "\n",
        "**Role**\n",
        "\n",
        "1.Weights represent the importance of each input feature.\n",
        "\n",
        "2.Large weight ‚Üí very important feature\n",
        "\n",
        "3.Small weight ‚Üí less important feature\n",
        "\n",
        "4.Negative weight ‚Üí inverse effect\n",
        "\n",
        "\n",
        "**2.Summation Unit + Bias (Linear Combiner)**\n",
        "\n",
        "The perceptron adds all weighted inputs and a bias (b).\n",
        "\n",
        "                               ùëç=‚àë(ùë•ùëñùë§ùëñ)+ùëè\n",
        "\n",
        "Role of Bias:\n",
        "\n",
        "Bias shifts the decision boundary left/right or up/down.\n",
        "\n",
        "Without bias ‚Üí model becomes very limited.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "***3.Activation Function (Decision Maker):***\n",
        "\n",
        "\n",
        "The activation function converts the calculated value into final output (0 or 1).\n",
        "\n",
        "Perceptron uses Step Function:\n",
        "\n",
        "Output={1,  ùëç‚â• 0 || 0, ùëç<0}\n",
        "\n",
        "\n",
        "Role\n",
        "It makes the final decision ‚Äî classification.\n"
      ],
      "metadata": {
        "id": "uEW6ibGfVZW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 02: [ Marks 10 ]\n",
        "\n",
        "What is a decision boundary in a perceptron?\n",
        "Explain how the equation\n",
        "w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + b = 0\n",
        "represents a decision boundary geometrically."
      ],
      "metadata": {
        "id": "_tPnXmkMVi8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Answer 02:\n",
        "\n",
        "A decision boundary is the line or surface  that separates input data into different classes in a perceptron model.It it the point where the perceptron changes its decision from on class to another class(0 to 1).\n",
        "\n",
        "\n",
        "Geometrical Meaning of,\n",
        "W1X1+W2X2+b=0\n",
        "\n",
        "In a perceptron, the output depends on the value:\n",
        "\t‚Äã       Z=W1X1+W2X2+b\n",
        "\n",
        "1.if z > 0 == class 1\n",
        "2.if z < 0 == class 0\n",
        "\n",
        "The point where the model is undecided when:\n",
        "         Z = 0\n",
        "\n",
        "So, w1x1+w2x2+b=0\n",
        "      \n",
        "\n"
      ],
      "metadata": {
        "id": "oTQ9yUrlVk4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 03: [ Marks 15 ]\n",
        "\n",
        "Why is the perceptron called a linear classifier?\n",
        "Explain your answer using the concept of linear separability and logical gate examples such as AND, OR, and XOR."
      ],
      "metadata": {
        "id": "YiUWig4VVnXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Answer 03:\n",
        "\n",
        "A perceptron is called a linear classifier because it separates data using a linear decision boundary:\n",
        "             w1x1+w2x2+.....wnxn+b=0\n",
        "\n",
        "This equation represents a:\n",
        "\n",
        "1.line (2D)\n",
        "\n",
        "2.plane (3D)\n",
        "\n",
        "3.hyperplane (n-D)\n",
        "\n",
        "So the perceptron can only divide data into classes using a straight boundary, not a curved one.\n",
        "\n",
        "///\n",
        "linear equation , y=w1x1+w2x2+b\n",
        "\n",
        "and classsify as:\n",
        "   output = 1 if y>=0\n",
        "   output = 0 if < 0\n",
        "The equation w1x1+w2x2+b=0 forms a straight line.\n",
        "So the perceptron can only separate data using a straight boundary.\n",
        "If the data can be separated by a single straight line, it is called linearly separable.\n",
        "If it cannot, the perceptron cannot learn it.\n",
        "\n",
        "**AND gate:**\n",
        "\n",
        "\n",
        "Truth table:\n",
        "\n",
        "(0,0) ‚Üí 0\n",
        "\n",
        "(0,1) ‚Üí 0\n",
        "\n",
        "(1,0) ‚Üí 0\n",
        "\n",
        "(1,1) ‚Üí 1\n",
        "\n",
        "\n",
        "Only the point (1,1) belongs to class 1 and the rest belong to class 0.\n",
        "A straight line can separate (1,1) from the other three points.\n",
        "\n",
        "Choose weights:\n",
        "       w1‚Äã=1,w2‚Äã=1,b=‚àí1.5\n",
        "\n",
        "compute:\n",
        "\n",
        "For (0,0): 0 + 0 ‚àí 1.5 = ‚àí1.5 ‚Üí 0\n",
        "\n",
        "For (0,1): 0 + 1 ‚àí 1.5 = ‚àí0.5 ‚Üí 0\n",
        "\n",
        "For (1,0): 1 + 0 ‚àí 1.5 = ‚àí0.5 ‚Üí 0\n",
        "\n",
        "For (1,1): 1 + 1 ‚àí 1.5 = 0.5 ‚Üí 1\n",
        "\n",
        "So perceptron correctly learns AND because the data is linearly separable.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**OR gate**\n",
        "True Table:\n",
        "\n",
        "(0,0) ‚Üí 0\n",
        "\n",
        "(0,1) ‚Üí 1\n",
        "\n",
        "(1,0) ‚Üí 1\n",
        "\n",
        "(1,1) ‚Üí 1\n",
        "\n",
        "Only (0,0) is class 0 and others are class 1.\n",
        "A straight line can separate them.\n",
        "\n",
        "Choose weights:\n",
        "      w1‚Äã=1,w2‚Äã=1,b=‚àí0.5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Compute:\n",
        "\n",
        "(0,0): ‚àí0.5 ‚Üí 0\n",
        "\n",
        "(0,1): 0.5 ‚Üí 1\n",
        "\n",
        "(1,0): 0.5 ‚Üí 1\n",
        "\n",
        "(1,1): 1.5 ‚Üí 1\n",
        "Perceptron learns OR because it is linearly separable.\n",
        "\n",
        "**XOR gate**\n",
        "\n",
        "Truth table:\n",
        "\n",
        "(0,0) ‚Üí 0\n",
        "\n",
        "(0,1) ‚Üí 1\n",
        "\n",
        "(1,0) ‚Üí 1\n",
        "\n",
        "(1,1) ‚Üí 0\n",
        "\n",
        "Here class-1 points are (0,1) and (1,0), and class-0 points are (0,0) and (1,1).\n",
        "They lie diagonally opposite each other.\n",
        "\n",
        "\n",
        "No single straight line can separate these two groups at the same time.\n",
        "Therefore no weights\n",
        "ùë§1,ùë§2,ùëè exist that satisfy all conditions.\n",
        "\n",
        "So the perceptron fails for XOR because it is not linearly separable.\n",
        "\n",
        "the perceptron is called a linear classifier because it can correctly classify only linearly separable problems such as AND and OR, but cannot classify non-linear problems like XOR."
      ],
      "metadata": {
        "id": "kTpWEibjaGmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 04: [ Marks 15 ]\n",
        "\n",
        "Write the perceptron weight update rule and explain it intuitively.\n",
        "Why are the weights updated only when the prediction is incorrect?"
      ],
      "metadata": {
        "id": "Vh-CVlcIZMdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Answer 04:\n",
        "\n",
        "The perceptron updates its weights using:\n",
        "\n",
        "       winew‚Äã=wiold‚Äã+Œ∑(t‚àíy)xi‚Äã\n",
        "         bnew=bold+Œ∑(t‚àíy)\n",
        "Where\n",
        "\n",
        "ùë§i = weight of input\n",
        "\n",
        "b = bias\n",
        "\n",
        "Œ∑ = learning rate\n",
        "\n",
        "t = true (target) output\n",
        "\n",
        "y = predicted output\n",
        "\n",
        "\n",
        "The perceptron learns by correcting mistake:\n",
        " Error =(ùë°‚àíùë¶)\n",
        "\n",
        "New weight = Old weight + Correction based on error\n",
        "\n",
        "**Correct prediction**\n",
        "\n",
        "If prediction is correct:t=y‚áí(t‚àíy)=0\n",
        "\n",
        "No update occurs.\n",
        "Meaning:\n",
        "The decision boundary already classifies the point correctly, so no learning is needed.\n",
        "Predicted 0 but should be 1 (Missed positive):\n",
        "\n",
        "t=1,y=0‚áí(t‚àíy)=+1\n",
        "\n",
        "Weights increase in direction of the input.\n",
        "\n",
        "The decision boundary moves toward the point so it becomes positive next time.\n",
        "\n",
        "Predicted 1 but should be 0 (False positive):\n",
        "t=0,y=1‚áí(t‚àíy)=‚àí1\n",
        "\n",
        "**Weights decrease.**\n",
        "\n",
        "The boundary moves away from the point.\n",
        "\n",
        "\n",
        "The perceptron updates weights using\n",
        "   wi = wi+Œ∑(t - y)xi\n",
        "\n",
        "It adjusts the decision boundary toward misclassified points and away from wrongly accepted points.\n",
        "Weights are updated only when prediction is incorrect because only errors indicate the boundary needs correction; correct predictions require no change."
      ],
      "metadata": {
        "id": "rfdsvUWfaJJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 05: [ Marks 10 ]\n",
        "\n",
        "Why does a single-layer perceptron fail to solve the XOR problem?\n",
        "What does this limitation tell us about the need for multilayer neural networks?"
      ],
      "metadata": {
        "id": "WIr6YmxaZNli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Answer 05:\n",
        "\n",
        "A single-layer perceptron fails to solve the XOR problem because XOR is not linearly separable.\n",
        "\n",
        "\n",
        "A single-layer perceptron can create only one linear decision boundary a straight line .\n",
        "But in XOR, no single straight line can separate the output classes correctly.\n",
        "\n",
        "Linear models are not always sufficient\n",
        "\n",
        "Real-world data often has:\n",
        "\n",
        "Complex patterns\n",
        "\n",
        "Non-linear relationships\n",
        "\n",
        "A single-layer perceptron can‚Äôt capture these."
      ],
      "metadata": {
        "id": "RVJMptexaKjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 06: [ Marks 20 ]\n",
        "\n",
        "What is meant by the ‚Äúperceptron Learning Rule‚Äù or weight adjustment method?\n",
        "Why can adjusting one weight affect the classification of other points?"
      ],
      "metadata": {
        "id": "t7wLPZTPZOnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Answer 06:\n",
        "\n",
        "\n",
        "The Perceptron Learning Rule (or weight adjustment rule) is the method used to train a perceptron. It tells us how to update the weights whenever the perceptron makes a mistake in classifying a training example.\n",
        "\n",
        "Basic idea:\n",
        "\n",
        "1.If the perceptron classifies a point correctly, do nothing.\n",
        "\n",
        "2.If it classifies a point incorrectly, adjust the weights so the output moves closer to the correct value.\n",
        "\n",
        "Mathematical formula:\n",
        "     winew‚Äã=wiold‚Äã+Œîwi‚Äã\n",
        "\n",
        "Where the change in weight is:\n",
        "    Œîwi‚Äã=Œ∑‚ãÖ(d‚àíy)‚ãÖxi‚Äã\n",
        "\n",
        "wi = weight for input\n",
        "Œ∑ = learning rate\n",
        "d = desired/target output\n",
        "y = actual output of the perceptron\n",
        "xi = input feature\n",
        "\n",
        "\n",
        "Explanation in words:\n",
        "Increase the weight if the perceptron output is too low.\n",
        "Decrease the weight if the output is too high.\n",
        "The amount of change is proportional to input value and error (d ‚àí y)\n",
        "\n",
        "***Why can adjusting one weight affect the classification of other points?***\n",
        "\n",
        "\n",
        "A perceptron uses a single weight vector\n",
        "w for all input points, not just one.\n",
        "\n",
        "Each weight contributes to the calculation of the net input for every training point:\n",
        "net input=i‚àëwixi\n",
        "So, changing a weight to correct one point also changes the net input for all other points, which may:\n",
        "Correctly classify some points.and incorrectly classify previously correct points\n",
        "\n"
      ],
      "metadata": {
        "id": "qNmHw4tnaMFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 07: [ Marks 20 ]\n",
        "\n",
        "What are the main limitations of a single-layer perceptron?\n",
        "How does the idea of using more than one layer (MLP) help overcome these limitations at a high level accoriding to you?\n",
        "\n"
      ],
      "metadata": {
        "id": "zZMx7oNaZPqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Answer 07:\n",
        "\n",
        "**Main Limitations of a Single-Layer Perceptron**\n",
        "\n",
        "A single-layer perceptron is the simplest type of neural network: it has an input layer and an output layer (no hidden layers). While it can handle some simple problems, it has significant limitations:\n",
        "\n",
        "A perceptron can only classify data if a straight line (or hyperplane in higher dimensions) can separate the classes.\n",
        "\n",
        "Works: Classifying points that form two clusters separated by a line.\n",
        "\n",
        "Fails: XOR problem ‚Äî inputs (0,0),(1,1) ‚Üí 0 and (0,1),(1,0) ‚Üí 1 cannot be separated by a single line\n",
        "\n",
        "It cannot capture complex patterns or interactions between features.\n",
        "\n",
        "Real-world data is often non-linear. A single-layer perceptron cannot draw curved or complex decision boundaries.\n",
        "\n",
        "A Multi-Layer Perceptron (MLP) adds one or more hidden layers between the input and output. This simple change solves many limitations:\n",
        "\n",
        "Hidden layers with non-linear activation functions (like ReLU, sigmoid, or tanh) allow the network to approximate any complex function.\n",
        "Each hidden layer transforms the input space into a new feature space, enabling the network to capture complex feature interactions.\n",
        "\n",
        "\n",
        "Multiple layers allow curved or irregular decision boundaries, making the network suitable for real-world tasks like image or speech recognition.\n",
        "An MLP with at least one hidden layer can approximate any continuous function, given enough neurons."
      ],
      "metadata": {
        "id": "L3cixQ3gaN0J"
      }
    }
  ]
}